Загрузка и стриминг данных
--------------------------

В **ADG** возможности загрузки и потоковой передачи (стриминг) данных позволяют принимать в кластер огромные и практически бесконечные объемы данных в масштабируемом и отказоустойчивом режиме. Скорость, с которой данные могут быть введены в **Grid**, очень высока и легко превышает миллионы событий в секунду на кластере среднего размера.


Загрузка данных
^^^^^^^^^^^^^^^^

**ADG** предоставляет несколько методов для загрузки данных из сторонней базы данных или другого источника.

Использование стандартных операций кэша *put(...)* или *putAll(...)* обычно неэффективно для загрузки больших объемов данных. **Grid** предлагает **API** *IgniteDataStreamer*, интеграцию с основными потоковыми технологиями и **API** *IgniteCache*, которые помогают более эффективно загружать большие объемы данных в кластер.


IgniteDataStreamer
~~~~~~~~~~~~~~~~~~

Потоки данных, заданные **API** *IgniteDataStreamer*, предназначены для внедрения больших объемов непрерывных данных в кэш **Grid**. Потоки строятся с возможностью масштабирования и отказоустойчивости и обеспечивают высокую производительность путем группирования записей прежде, чем они будут отправлены соответствующим элементам кластера.

.. important:: Потоки данных могут использоваться для загрузки большого объема данных в кэш в любое время, включая предварительную загрузку при запуске


IgniteCache.loadCache()
~~~~~~~~~~~~~~~~~~~~~~~

В случае если сторонняя база данных хранит данные, а приложения используют **SQL**, **Scan** и другие расширенные запросы, **ADG** требует предварительной загрузки данных с диска в оперативную память.

.. important:: Персистенс ADG не требует прогрева оперативной памяти при перезапуске. Таким образом, методы загрузки, основаные на *IgniteCache.loadCache()*, не актуальны для данного вида персистентного хранения

Для предварительной загрузки данных из стороннего хранилища, такого как реляционная база данных, следует использовать метод *IgniteCache.loadCache()*, позволяющий загружать данные кэша без передачи ключей, которые необходимо загрузить.

Метод *IgniteCache.loadCache()* делегирует метод *CacheStore.loadCache()* для каждого элемента кластера. Чтобы вызвать загрузку только на локальном узле кластера, необходимо использовать метод *IgniteCache.localLoadCache()*.

.. important:: В случае сегментированных кэшей и персистентности третьей стороны, такой как реляционная база данных, не сопоставленные с этим узлом ключи, так же как их овные и резервные копии, будут автоматически удалены. Это не относится к **Grid Persistent Store**, где каждый узел хранит только те данные, для которых он является основным или резервным

Далее приведен пример использования реализации *CacheStore.loadCache()* для персистентности третьей стороны.

+ Java:

  ::
  
   public class CacheJdbcPersonStore extends CacheStoreAdapter<Long, Person> {
   	...
     // This method is called whenever "IgniteCache.loadCache()" or
     // "IgniteCache.localLoadCache()" methods are called.
     @Override public void loadCache(IgniteBiInClosure<Long, Person> clo, Object... args) {
       if (args == null || args.length == 0 || args[0] == null)
         throw new CacheLoaderException("Expected entry count parameter is not provided.");
   
       final int entryCnt = (Integer)args[0];
   
       Connection conn = null;
   
       try (Connection conn = connection()) {
         try (PreparedStatement st = conn.prepareStatement("select * from PERSONS")) {
           try (ResultSet rs = st.executeQuery()) {
             int cnt = 0;
   
             while (cnt < entryCnt && rs.next()) {
               Person person = new Person(rs.getLong(1), rs.getString(2), rs.getString(3));
   
               clo.apply(person.getId(), person);
   
               cnt++;
             }
           }
         }
       }
       catch (SQLException e) {
         throw new CacheLoaderException("Failed to load values from cache store.", e);
       }
     }
     ...
   }


Загрузка данных Partition-aware
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~






Стриминг данных
^^^^^^^^^^^^^^^

Как работает стриминг:

1. Клиентские узлы вводят конечные или непрерывные потоки данных в кэш **Grid**, используя **Grid Data Streamers**.
2. Данные автоматически разделяются между узлами **Grid**, и каждый узел получает равное количество данных.
3. Потоковые данные могут совместно и одновременно обрабатываться на узлах данных **Grid**.
4. Клиенты также могут выполнять параллельные SQL-запросы для потоковых данных.

Потоки данных определяются **API** *IgniteDataStreamer* и создаются для ввода больших объемов непрерывных потоков данных в кэш **Grid**. Потоки данных построены с возможностью масштабирования и отказоустойчивости и обеспечивают семантику по крайней мере один раз для всех данных, передаваемых в **ADG**.

Для запроса потоковых данных можно использовать полный набор возможностей индексирования данных в **Grid**, вместе с кэшированными запросами **SQL**, **TEXT** и **Predicate**.

**ADG** интегрируется с основными потоковыми технологиями и платформами, такими как **Kafka**, **Camel**, **Storm** или **JMS**, чтобы обеспечить еще более продвинутые возможности потоковой передачи на архитектуре **Grid**.

