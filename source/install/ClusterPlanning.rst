Руководство по планированию кластера
=====================================

Руководство по планированию кластера включает в себя следующие главы необходимые для прочтения перед непосредственной установкой кластера: 

+ `Рекомендации по аппаратному обеспечению для Apache Hadoop`_
+ `Рекомендации по партиционированию файловой системы`_


Рекомендации по аппаратному обеспечению для Apache Hadoop
-----------------------------------------------------------

Рабочие нагрузки **Hadoop** и **HBase**, как правило, сильно различаются, и требуется опыт для правильного прогнозирования объемов хранилища, вычислительной мощности и межузловой связи, которые потребуются для выполнения различных видов работ.

В главе содержится информация о выборе соответствующих аппаратных компонентов для оптимального баланса между производительностью и начальными, а также текущими затратами. Краткое резюме приведено в разделе `Заключение`_.

**Hadoop** -- это программный фреймворк, поддерживающий крупномасштабный анализ распределенных данных на обычных серверах. **Arenadata** является участником инициатив с открытым исходным кодом (**Apache Hadoop**, **HDFS**, **Pig**, **Hive**, **HBase**, **ZooKeeper**) и имеет большой опыт управления кластерами **Hadoop** на производственном уровне. **Arenadata** рекомендует следовать принципам проектирования, которые обеспечивают масштабное развертывание в гиперпространстве. Для кластера **Hadoop** или **HBase** крайне важно точно спрогнозировать размер, тип, частоту и задержку для задач на выполнение. Начиная с **Hadoop** или **HBase**, есть возможность получения опыта, измеряя фактические рабочие нагрузки во время пилотного проекта. Таким образом, можно легко масштабировать пилотную среду, не внося существенных изменений в существующие серверы, программное обеспечение, стратегии развертывания и сетевое подключение.


Типичный кластер Hadoop
^^^^^^^^^^^^^^^^^^^^^^^^

Кластеры **Hadoop** и **HBase** имеют два типа машин:

+ Masters -- HDFS NameNode, YARN ResourceManager и HBase Master;
+ Slaves -- HDFS DataNodes, YARN NodeManagers и HBase RegionServers.

Узлы DataNodes, NodeManagers и HBase RegionServers размещаются и разворачиваются совместно для оптимальной локализации данных. Кроме того, HBase требует использования отдельного компонента (**ZooKeeper**) для управления кластером **HBase**.

**Arenadata** рекомендует разделять master (основные) и slave (подчиненные) узлы, поскольку:

+ Рабочие нагрузки задачи/приложения на подчиненных узлах должны быть изолированы от основных;
+ Подчиненные узлы часто выводятся из эксплуатации для технического обслуживания.

В целях экспертизы можно развернуть **Hadoop**, используя инсталляцию с одним узлом (при условии, что все основные и подчиненные процессы находятся на одной машине). Для небольшого двухузлового кластера можно установить NameNode и ResourceManager на master-узле, а DataNode и NodeManager на slave-узле.

Кластеры из трех или более машин обычно используют один NameNode и ResourceManager со всеми другими узлами в качестве подчиненных. Кластер High-Availability использует первичный и вторичный NameNode, также как может использовать первичный и вторичный ResourceManager.

Как правило, кластер **Hadoop** среднего и большого размера состоит из двухуровневой или трехуровневой архитектуры, построенной на монтируемых в стойку серверах. Каждая стойка серверов соединена с помощью коммутатора *1 Gigabyte Ethernet* (GbE). Каждый коммутатор уровня стойки подключен к коммутатору уровня кластера (который, как правило, является коммутатором с большей плотностью портов *10GbE*). Коммутаторы кластерного уровня могут также соединяться с другими коммутаторами уровня кластера или даже восходить к другому уровню инфраструктуры.


Типичные шаблоны рабочей нагрузки для Hadoop
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Дисковое пространство, пропускная способность ввода-вывода (необходимая для **Hadoop**) и вычислительная мощность (необходимая для процессов **MapReduce**) являются наиболее важными параметрами для точного определения размера оборудования. Кроме того, при установке **HBase** также необходимо проанализировать приложение и его требования к памяти, поскольку **HBase** является компонентом, интенсивно использующим память. Исходя из типичных вариантов использования **Hadoop**, в рабочих средах наблюдаются следующие шаблоны нагрузки:

+ **Balanced Workload** -- сбалансированная

Если рабочие нагрузки распределены равномерно между различными типами заданий (привязка к процессору, к дисковому вводу/выводу или к сетевому вводу/выводу), кластер имеет сбалансированный шаблон рабочей нагрузки. Это хорошая конфигурация по умолчанию для неизвестных или развивающихся нагрузок.

+ **Compute Intensive** -- ресурсоемкая

Рабочие нагрузки связаны с ЦП и характеризуются необходимостью большого количества процессоров и большого объема памяти для хранения данных в процессе. Шаблон использования типичен для обработки естественного языка или рабочих нагрузок HPCC.

+ **I/O Intensive** -- интенсивный ввод/вывод

Типичное задание MapReduce (например, сортировка) требует очень мало вычислительной мощности. Вместо этого оно больше зависит от связанной способности ввода/вывода кластера (например, при большом объеме холодных данных). Для такого типа рабочей нагрузки рекомендуется закладывать больше дисков в коробку.

+ **Unknown or evolving workload patterns** -- неизвестные или развивающиеся шаблоны рабочей нагрузки

Изначально можно не знать возможные шаблоны рабочей нагрузки. И, как правило, первые задания, переданные в **Hadoop**, сильно отличаются от фактических заданий, которые будут выполняться в производственной среде. По этим причинам **Arenadata** рекомендует либо использовать конфигурацию сбалансированной рабочей нагрузки, либо инвестировать в пилотный кластер **Hadoop** и планировать развитие его структуры по мере анализа шаблонов рабочей нагрузки в среде.


Early Deployments
^^^^^^^^^^^^^^^^^^^^

При первом знакомстве с **Hadoop** или **HBase** рекомендуется начинать с относительно небольшого экспериментального кластера, рассчитанного на Balanced Workload и получать опыт путем измерения фактических рабочих нагрузок во время пилотного проекта.

Для пилотного развертывания можно начать с 1U-машины и использовать следующие рекомендации:

+ Два четырехъядерных процессора;
+ От *12* до *24 ГБ* памяти;
+ От четырех до шести дисков емкостью *2 ТБ*.






Заключение
^^^^^^^^^^^


Рекомендации по партиционированию файловой системы
---------------------------------------------------
