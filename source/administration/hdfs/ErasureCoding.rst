HDFS Erasure Coding
=====================

+ `Цель`_
+ `Background`_
+ `Архитектура`_
+ `Развертывание`_
+ `Ограничения`_

Цель
------

Репликация всегда дорогостоящая -- схема репликации по умолчанию (*3x*) в **HDFS** имеет *200%* накладных расходов в области хранения и других ресурсах (например, пропускная способность сети). Однако для теплых и холодных наборов данных с относительно низким уровнем операций ввода-вывода дополнительные реплики блоков редко доступны во время обычных операций, но все равно потребляют тот же объем ресурсов, что и первая реплика.

Поэтому естественным улучшением является использование Erasure Coding (EC) вместо репликации, что обеспечивает тот же уровень отказоустойчивости при гораздо меньшем объеме памяти. В типичных настройках Erasure Coding накладные расходы на хранение не превышают *50%*. Коэффициент репликации файла EC не имеет смысла, он всегда равен *1* и не может быть изменен с помощью -setrep команды.


Background
-------------

В системах хранения наиболее заметным использованием Erasure Coding является избыточный массив недорогих дисков (RAID). RAID реализует EC посредством чередования, которое делит логически последовательные данные (например, файл) на более мелкие единицы (например, бит, байт или блок) и сохраняет последовательные единицы на разных дисках. Далее данная единица распределения чередования называется *чередующейся ячейкой* (или просто *ячейкой*). Для каждой полосы исходных ячеек данных вычисляется и сохраняется определенное количество ячеек четности -- процесс, который называется *кодированием*. Ошибка в любой чередующейся ячейке может быть исправлена путем вычисления декодирования на основе сохранившихся данных и четности ячеек.

Интеграция Erasure Coding с **HDFS** может повысить эффективность хранилища, обеспечивая при этом такую же долговечность данных, что и традиционные развертывания **HDFS** на основе репликации. Например, *3х*-реплицированный файл с *6* блоками будет занимать 6 * 3 = 18 блоков дискового пространства. Но при развертывании EC (*6* данных, *3* четности) он будет занимать только 9 блоков дискового пространства.


Архитектура
--------------

В контексте Erasure Coding чередование имеет несколько важных преимуществ. Во-первых, позволяется онлайн запись данных непосредственно в формате EC, избегая фазы преобразования и немедленно экономя место для хранения. Это также повышает производительность последовательного ввода-вывода за счет параллельного использования нескольких дисков, что особенно желательно в кластерах с высокопроизводительными сетями. Во-вторых, небольшие файлы естественным образом распределяются на несколько узлов данных DataNodes и устраняется необходимость объединения нескольких файлов в одну группу кодирования. Это значительно упрощает операции с файлами, такие как удаление, quota reporting и миграция между объединенными пространствами имен Namespaces.

В типичных кластерах **HDFS** небольшие файлы могут занимать более *3/4* общего объема памяти. Чтобы лучше поддерживать небольшие файлы, на этом первом этапе работы **HDFS** поддерживает EC с чередованием. В будущем **HDFS** также будет поддерживать смежную компоновку EC.

Расширения NameNode -- чередующиеся файлы **HDFS**, логически состоящие из групп блоков, каждая из которых содержит определенное количество внутренних блоков. Чтобы уменьшить потребление памяти NameNode от этих дополнительных блоков, введен новый иерархический протокол именования блоков. Идентификатор группы блоков может быть выведен из идентификатора любого из ее внутренних блоков. Это позволяет управлять на уровне группы блоков, а не на уровне одного блока.

Клиентские расширения -- клиентские пути чтения и записи улучшены для параллельной работы с несколькими внутренними блоками в группе блоков. На пути вывода/записи *DFSStripedOutputStream* управляет набором потоков данных, по одному для каждого DataNode, хранящего внутренний блок в текущей группе блоков. Стримеры в основном работают асинхронно. Координатор отвечает за операции над всей группой блоков, включая завершение текущей группы блоков, выделение новой группы блоков и так далее. На пути ввода/чтения *DFSStripedInputStream* преобразует запрошенный логический байтовый диапазон данных в виде диапазонов во внутренние блоки, хранящиеся в DataNodes. Затем параллельно выдаются запросы на чтение. А при сбоях выдаются дополнительные запросы на чтение для декодирования.

Расширения DataNode -- DataNode запускает дополнительную задачу *ErasureCodingWorker* (ECWorker) для фонового восстановления сбойных блоков Erasure Coded. Сбойные блоки EC обнаруживаются NameNode, который затем выбирает DataNode для выполнения работы по восстановлению. Задача восстановления передается как ответ на heartbeat-сообщение. Этот процесс аналогичен тому, как реплицированные блоки повторно реплицируются при сбое. Реконструкция выполняет три ключевые задачи:

+ Чтение данных из исходных узлов: входные данные считываются параллельно из исходных узлов с помощью выделенного пула потоков. Основываясь на политике EC, он планирует запросы на чтение для всех исходных целей и считывает только минимальное количество входных блоков для восстановления;

+ Декодирование данных и генерирование выходных данных: новые данные и блоки четности декодируются из входных данных. Все недостающие данные и блоки четности декодируются вместе;

+ Передача сгенерированных блоков данных на целевые узлы: после завершения декодирования восстановленные блоки передаются на целевые DataNodes.

https://hadoop.apache.org/docs/r3.1.2/hadoop-project-dist/hadoop-hdfs/HDFSErasureCoding.html



Развертывание
---------------


Ограничения
-------------


