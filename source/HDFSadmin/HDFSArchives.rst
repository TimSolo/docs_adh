Архивы Hadoop
-------------

**Распределенная файловая система Hadoop** (**HDFS**) предназначена для хранения и обработки больших наборов данных, но при этом **HDFS** может быть менее эффективна при хранении большого количества мелких файлов. Когда в **HDFS** хранится много мелких файлов, они занимают большую часть пространства имен. В результате место на диске недоиспользуется из-за ограничения пространства имен.

**Архивы Hadoop** (**HAR**) используются для устранения ограничений пространства имен, связанных с хранением большого количества мелких файлов. **Архив Hadoop** позволяет упаковывать небольшие файлы в блоки **HDFS** более эффективно, тем самым сокращая использование памяти **NameNode**, сохраняя прозрачный доступ к файлам. **Архивы Hadoop** также совместимы с **MapReduce**, обеспечивая прозрачный доступ к исходным файлам с помощью заданий **MapReduce**.


Введение
^^^^^^^^

**HDFS** предназначена для хранения и обработки больших массивов данных (терабайт). Например, большой производственный кластер может иметь 14 ПБ дискового пространства и хранить 60 миллионов файлов.

Однако хранение большого количества мелких файлов в **HDFS** неэффективно. Обычно файл считается «маленьким», когда его размер существенно меньше размера блока **HDFS**, который по умолчанию равен 256 МБ в **ADH**. Файлы и блоки являются объектами имен в **HDFS**, что означает, что они занимают пространство имен (место в **NameNode**). Таким образом, емкость пространства имен системы ограничена физической памятью **NameNode**.

Когда в системе хранится много мелких файлов, они занимают большую часть пространства имен. Как следствие, дисковое пространство недоиспользуется из-за ограничения пространства имен. В одном реальном примере производственный кластер имел 57 миллионов файлов размером менее 256 МБ, при этом каждый из этих файлов занимал один блок в **NameNode**. Эти мелкие файлы использовали 95% пространства имен, но занимали только 30% дискового пространства кластера.

**HAR** могут использоваться для устранения ограничений пространства имен, связанных с хранением большого количества мелких файлов. **HAR** упаковывает несколько мелких файлов в большой, обеспечивая прозрачный доступ к исходным файлам (без расширения файлов).

**HAR** увеличивает масштабируемость системы за счет сокращения использования пространства имен и уменьшения нагрузки на работу в **NameNode**. Это улучшение оптимизирует память в **NameNode** и распределяет управление пространством имен по нескольким **NameNodes**.

**HAR** также совместим с **MapReduce**, он обеспечивает параллельный доступ к исходным файлам с помощью заданий **MapReduce**.



Компоненты архивов Hadoop
^^^^^^^^^^^^^^^^^^^^^^^^^


Формат модели данных HAR
~~~~~~~~~~~~~~~~~~~~~~~~~

Формат модели данных архивов **Hadoop** имеет следующий вид:
::

 foo.har/_masterindex //stores hashes and offsets
 foo.har/_index //stores file statuses
 foo.har/part-[1..n] //stores actual file data

Файлы данных хранятся в нескольких файлах, которые индексируются для сохранения первоначального разделения данных. Кроме того, файлы доступны параллельно с помощью программ **MapReduce**. В индексах файлов также записываются исходные структуры дерева каталогов и статус файла.



Файловая система HAR
~~~~~~~~~~~~~~~~~~~~

Большинство архивных систем, таких как **tar**, являются инструментами для архивирования и деархивации. Как правило, они не вписываются в фактический уровень файловой системы и, следовательно, не являются прозрачными для разработчика приложения, поскольку пользователь должен предварительно деархивировать (расширять) архив перед использованием.

**Архив Hadoop** интегрируется с интерфейсом **файловой системы Hadoop**. *HarFileSystem* реализует интерфейс *FileSystem* и предусматривает доступ через *har://*. Это обеспечивает прозрачность архивных файлов и структур дерева каталогов для пользователей. Доступ к файлам в **HAR** можно получить напрямую, без его расширения.

Например, следующая команда для копирования файла **HDFS** в локальный каталог:

:command:`hdfs dfs –get hdfs://namenode/foo/file-1 localdir`

Предположим, что **Архив Hadoop** *bar.har* создан из каталога *foo*. С помощью **HAR** команда для копирования исходного файла становится следующей:

:command:`hdfs dfs –get har://namenode/bar.har/foo/file-1 localdir`

Пользователям следует изменить пути URI. Но при этом пользователи могут создать символическую ссылку (из *hdfs://namenode/foo* для *har://namenode/bar.har/foo* в примере выше), и тогда изменять URI не будет необходимости. В любом случае, *HarFileSystem* вызывается автоматически для обеспечения доступа к файлам в **HAR**. Из-за этого прозрачного слоя **HAR** совместим с **API Hadoop**, **MapReduce**, интерфейсом командной строки **оболочки FS** и приложениями более высокого уровня, такими как **Pig**, **Zebra**, **Streaming**, **Pipes** и **DistCp**.



Инструмент архивации Hadoop
~~~~~~~~~~~~~~~~~~~~~~~~~~~

**Архивы Hadoop** могут быть созданы с использованием инструмента архивации **Hadoop**. Инструмент архивации использует **MapReduce** для эффективного параллельного создания **архивов Hadoop**. Инструмент вызывается с помощью команды:

:command:`hadoop archive -archiveName name -p <parent> <src>* <dest>`

Список файлов генерируется путем рекурсивного перемещения исходных каталогов, а затем список разбивается на карту входящих задач. Каждая задача создает файл (около 2 ГБ, настраивается) из подмножества исходных файлов и выводит метаданные. Наконец, reduce task собирает метаданные и генерирует индексные файлы.



Создание архива Hadoop
^^^^^^^^^^^^^^^^^^^^^^

Инструмент архивации **Hadoop** вызывается следующей командой:

:command:`hadoop archive -archiveName name -p <parent> <src>* <dest>`

Где *-archiveName* - это имя создающегося архива. В имени архива должно быть указано расширение *.har*. Аргумент *<parent>* используется для указания относительного пути к папке, в которой файлы будут архивироваться в **HAR**. Например:

:command:`hadoop archive -archiveName foo.har -p /user/hadoop dir1 dir2 /user/zoo`

В данном примере создается архив с использованием */user/hadoop* в качестве каталога архива. Каталоги */user/hadoop/dir1* и */user/hadoop/dir2* будут заархивированы в архиве */user/zoo/foo.har*.

.. important:: Архивирование не удаляет исходные файлы. При необходимости удаления входных файлов после создания архива (в целях сокращения пространства имен), исходные файлы удаляются вручную

Хотя команда архивации **Hadoop** может быть запущена из файловой системы хоста, файл архива создается в **HDFS** из существующих каталогов. Если ссылаться на каталог в файловой системе хоста, а не на **HDFS**, выдается следующая ошибка:

:command:`The resolved paths set is empty. Please check whether the srcPaths exist, where srcPaths = [</directory/path>]`

Для создания каталогов **HDFS**, используемых в предыдущем примере, необходимо выполнить следующую команду:
::

 hdfs dfs -mkdir /user/zoo
 hdfs dfs -mkdir /user/hadoop
 hdfs dfs -mkdir /user/hadoop/dir1
 hdfs dfs -mkdir /user/hadoop/dir2



Просмотр файлов в архивах Hadoop
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Команда *hdfs dfs -ls* может использоваться для поиска файлов в архивах **Hadoop**. Используя пример архива */user/zoo/foo.har*, созданный в предыдущем разделе, необходимо использовать следующую команду для вывода списка файлов в архиве:

:command:`hdfs dfs -ls har:///user/zoo/foo.har/`

Результатом будет:
::

 har:///user/zoo/foo.har/dir1
 har:///user/zoo/foo.har/dir2

Данные архивы были созданы с помощью следующей команды:

:command:`hadoop archive -archiveName foo.har -p /user/hadoop dir1 dir2 /user/zoo`

Если изменить данную команду на:

:command:`hadoop archive -archiveName foo.har -p /user/ hadoop/dir1 hadoop/dir2 /user/zoo`

И затем выполнить следующую команду:

:command:`hdfs dfs -ls -R har:///user/zoo/foo.har`

То результатом будет:
::
 
 har:///user/zoo/foo.har/hadoop
 har:///user/zoo/foo.har/hadoop/dir1
 har:///user/zoo/foo.har/hadoop/dir2

Следует оборатить внимание, что с измененным родительским аргументом файлы заархивированы относительно */user/*, а не */user/hadoop*.



Hadoop Archives и MapReduce
^^^^^^^^^^^^^^^^^^^^^^^^^^^

Чтобы использовать **архивы Hadoop** с **MapReduce**, необходимо ссылаться на файлы несколько иначе, чем на файловую систему по умолчанию. Если есть **архив Hadoop**, хранящийся в **HDFS** в */user/ zoo/foo.har*, следует указать каталог ввода как *har:///user/zoo/foo.har*, чтобы использовать его как **MapReduce**. Поскольку **архивы Hadoop** отображаются как файловая система, **MapReduce** может использовать все логические входные файлы в **архивы Hadoop** в качестве входных данных.
















