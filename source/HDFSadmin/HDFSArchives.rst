HAR. Архивы Hadoop
===================

Распределенная файловая система **Hadoop** -- **HDFS** -- предназначена для хранения и обработки больших наборов данных, но при этом **HDFS** может быть менее эффективна при хранении большого количества мелких файлов, так как они занимают большую часть пространства имен. В результате место на диске недоиспользуется из-за ограничения пространства имен.

Архивы **Hadoop** -- **HAR** -- используются для устранения ограничений пространства имен, связанных с хранением большого количества мелких файлов. Архив **Hadoop** позволяет упаковывать небольшие файлы в блоки **HDFS** более эффективно, тем самым сокращая использование памяти *NameNode*, сохраняя прозрачный доступ к файлам. **HAR** также совместимы с *MapReduce*, обеспечивая прозрачный доступ к исходным файлам.

**HDFS** предназначена для хранения и обработки больших массивов данных (терабайт). Например, большой продуктивный кластер может иметь *14 ПБ* дискового пространства и хранить *60* миллионов файлов.

Однако хранение большого количества мелких файлов в **HDFS** неэффективно. Обычно файл считается «маленьким», когда его размер существенно меньше размера блока **HDFS**, который в **ADH** по умолчанию равен *256 МБ*. Файлы и блоки являются объектами имен в **HDFS**, что означает, что они занимают пространство имен (место в *NameNode*). Таким образом, емкость пространства имен системы ограничена физической памятью *NameNode*.

Когда в системе хранится много мелких файлов, они занимают большую часть пространства имен. Как следствие, дисковое пространство недоиспользуется из-за ограничения пространства имен. В одном реальном примере кластер имел *57* миллионов файлов размером менее *256 МБ*, при этом каждый из этих файлов занимал один блок в *NameNode*. Эти мелкие файлы использовали *95%* пространства имен, но занимали только *30%* дискового пространства кластера.

Архивы **HAR** могут использоваться для устранения ограничений пространства имен, связанных с хранением большого количества мелких файлов. **HAR** упаковывает несколько мелких файлов в большой, обеспечивая прозрачный доступ к исходным файлам (без расширения файлов). Таким образом **HAR** увеличивает масштабируемость системы за счет сокращения использования пространства имен и уменьшения нагрузки на работу в *NameNode*, оптимизирует память в *NameNode* и распределяет управление пространством имен по нескольким *NameNodes*. Кроме того, **HAR** обеспечивает параллельный доступ к исходным файлам с помощью заданий **MapReduce**.



Компоненты HAR
---------------


Формат модели данных 
^^^^^^^^^^^^^^^^^^^^^^

Формат модели данных архивов **Hadoop** имеет вид:
::

 foo.har/_masterindex //stores hashes and offsets
 foo.har/_index //stores file statuses
 foo.har/part-[1..n] //stores actual file data

Файлы данных хранятся в нескольких файлах, которые индексируются для сохранения первоначального разделения данных. Кроме того, файлы доступны параллельно с помощью *MapReduce*. В индексах файлов также записываются исходные структуры дерева каталогов и статус файла.



Файловая система HAR
^^^^^^^^^^^^^^^^^^^^^

Большинство архивных систем, таких как **tar**, являются инструментами для архивации и деархивации. Как правило, они не вписываются в фактический уровень файловой системы и, следовательно, не являются прозрачными для разработчика приложения, поскольку пользователь должен предварительно деархивировать (расширять) архив перед использованием.

**HAR** интегрируется с интерфейсом файловой системы **Hadoop**. *HarFileSystem* реализует интерфейс *FileSystem* и предусматривает доступ через *har://*. Это обеспечивает прозрачность архивных файлов и структур дерева каталогов для пользователей. Доступ к файлам в **HAR** можно получить напрямую, без его расширения.

Например, команда для копирования файла **HDFS** в локальный каталог:

  :command:`hdfs dfs –get hdfs://namenode/foo/file-1 localdir`

Предположив, что архив **Hadoop** *bar.har* создан из каталога *foo*, с помощью **HAR** команда для копирования исходного файла становится следующей:

  :command:`hdfs dfs –get har://namenode/bar.har/foo/file-1 localdir`

Пользователям следует изменить пути URI. Но при этом пользователи могут создать символическую ссылку (из *hdfs://namenode/foo* для *har://namenode/bar.har/foo* в примере выше), и тогда изменять URI не будет надобности. В любом случае, *HarFileSystem* вызывается автоматически для обеспечения доступа к файлам в **HAR**. Из-за этого прозрачного слоя **HAR** совместим с **API Hadoop**, *MapReduce*, интерфейсом командной строки оболочки **FS** и приложениями более высокого уровня, такими как **Pig**, **Zebra**, **Streaming**, **Pipes** и **DistCp**.



Инструмент архивации 
^^^^^^^^^^^^^^^^^^^^^

Архивы **Hadoop** могут быть созданы с помощью инструмента архивации **Hadoop**, он использует *MapReduce* для эффективного параллельного создания **HAR**. Инструмент вызывается с помощью команды:

  :command:`hadoop archive -archiveName name -p <parent> <src>* <dest>`

Список файлов генерируется путем рекурсивного перемещения исходных каталогов, а затем список разбивается на карту входящих задач. Каждая задача создает файл (около *2 ГБ*, настраивается) из подмножества исходных файлов и выводит метаданные. В итоге, *reduce task* собирает метаданные и генерирует индексные файлы.



Создание архива
----------------

Инструмент архивации вызывается следующей командой:

  :command:`hadoop archive -archiveName name -p <parent> <src>* <dest>`

Где ``-archiveName`` -- имя создающегося архива. В имени архива должно быть указано расширение *.har*. Аргумент ``<parent>`` используется для указания относительного пути к папке, в которой файлы будут архивироваться в **HAR**. Например:

  :command:`hadoop archive -archiveName foo.har -p /user/hadoop dir1 dir2 /user/zoo`

В приведенном примере создается архив с использованием */user/hadoop* в качестве каталога архива. Каталоги */user/hadoop/dir1* и */user/hadoop/dir2* будут заархивированы в архиве */user/zoo/foo.har*.

.. important:: Архивирование не удаляет исходные файлы. При необходимости удаления входных файлов после создания архива (в целях сокращения пространства имен), исходные файлы должны удаляться вручную

Хотя команда архивации может быть запущена из файловой системы хоста, файл архива создается в **HDFS** из существующих каталогов. Если ссылаться на каталог в файловой системе хоста, а не на **HDFS**, выдается ошибка:

  :command:`The resolved paths set is empty. Please check whether the srcPaths exist, where srcPaths = [</directory/path>]`

Для создания каталогов **HDFS**, используемых в предыдущем примере, необходимо выполнить команду:
::

 hdfs dfs -mkdir /user/zoo
 hdfs dfs -mkdir /user/hadoop
 hdfs dfs -mkdir /user/hadoop/dir1
 hdfs dfs -mkdir /user/hadoop/dir2



Просмотр файлов в архивах Hadoop
---------------------------------

Команда *hdfs dfs -ls* может использоваться для поиска файлов в архивах **Hadoop**. Используя пример архива */user/zoo/foo.har*, созданный в предыдущем разделе, необходимо применить следующую команду для вывода списка файлов в архиве:

  :command:`hdfs dfs -ls har:///user/zoo/foo.har/`

Результатом будет:
::

 har:///user/zoo/foo.har/dir1
 har:///user/zoo/foo.har/dir2

Архивы были созданы с помощью команды:

  :command:`hadoop archive -archiveName foo.har -p /user/hadoop dir1 dir2 /user/zoo`

Если изменить данную команду на:

  :command:`hadoop archive -archiveName foo.har -p /user/ hadoop/dir1 hadoop/dir2 /user/zoo`

И затем выполнить команду:

  :command:`hdfs dfs -ls -R har:///user/zoo/foo.har`

То результатом будет:
::
 
 har:///user/zoo/foo.har/hadoop
 har:///user/zoo/foo.har/hadoop/dir1
 har:///user/zoo/foo.har/hadoop/dir2

Следует оборатить внимание, что с измененным родительским аргументом файлы заархивированы относительно */user/*, а не */user/hadoop*.



Hadoop Archives и MapReduce
-----------------------------

Для использования **HAR** с *MapReduce* необходимо ссылаться на файлы несколько иначе, чем на файловую систему по умолчанию. Если есть архив **Hadoop**, хранящийся в **HDFS** в */user/ zoo/foo.har*, следует указать каталог ввода как *har:///user/zoo/foo.har*, чтобы использовать его как *MapReduce*. Поскольку **HAR** отображаются как файловая система, *MapReduce* может использовать все логические входные файлы в архивы **Hadoop** в качестве входных данных.

